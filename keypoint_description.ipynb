{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keypoint(Patch) Description\n",
    "  \n",
    "This project will be all about defining and training a convolutional neural network to perform keypoint  description. \n",
    "PyTorch tutorials are available at: https://github.com/yunjey/pytorch-tutorial\n",
    "\n",
    "\n",
    "The first step is to load and visualize the data you'll be working with. \n",
    "\n",
    "We will use below dataset in this project:\n",
    "###  The Photo Tourism dataset \n",
    "(http://phototour.cs.washington.edu/patches/default.htm)\n",
    "\n",
    "It is also available in PyTorch torchvision datasets:\n",
    "https://pytorch.org/docs/stable/_modules/torchvision/datasets/phototour.html#PhotoTour\n",
    "\n",
    "This dataset consists of 1024 x 1024 bitmap (.bmp) images, each containing a 16 x 16 array of image patches. Here are some examples:\n",
    "\n",
    "<table><tr><td><img src='images/patches0001.bmp'></td><td><img src='images/patches1482.bmp'></td></tr></table>    \n",
    "For details of how the scale and orientation is established, please see the paper:  \n",
    "<p class=\"style8\"><font size=\"2\">S. Winder and M. Brown. <strong>Learning Local Image \n",
    "\t\t\t\tDescriptors</strong>. To appear <i>International Conference on \n",
    "\t\t\t\tComputer Vision and Pattern Recognition (CVPR2007)</i> (</font><a href=\"http://research.microsoft.com/~swinder/papers/winder_brown_cvpr07.pdf\"><span class=\"style9\">pdf \n",
    "\t\t\t\t300Kb</span></a><font size=\"2\">)</font></p>\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import PIL\n",
    "import random\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import torch\n",
    "import torch.nn.init\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "from torch.autograd import Variable\n",
    "from copy import deepcopy, copy\n",
    "from config_profile import args\n",
    "from Utils import cv2_scale36, cv2_scale, np_reshape, np_reshape64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check GPU availability, using nvidia-smi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define PyTorch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletPhotoTour(dset.PhotoTour):\n",
    "    \"\"\"\n",
    "    From the PhotoTour Dataset it generates triplet samples\n",
    "    note: a triplet is composed by a pair of matching images and one of\n",
    "    different class.\n",
    "    \"\"\"\n",
    "    def __init__(self, train=True, transform=None, batch_size = None,load_random_triplets = False,  *arg, **kw):\n",
    "        super(TripletPhotoTour, self).__init__(*arg, **kw)\n",
    "        self.transform = transform\n",
    "        self.out_triplets = load_random_triplets\n",
    "        self.train = train\n",
    "        self.n_triplets = args.n_triplets\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        if self.train:\n",
    "            print('Generating {} triplets'.format(self.n_triplets))\n",
    "            self.triplets = self.generate_triplets(self.labels, self.n_triplets)\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_triplets(labels, num_triplets):\n",
    "        def create_indices(_labels):\n",
    "            inds = dict()\n",
    "            for idx, ind in enumerate(_labels):\n",
    "                if ind not in inds:\n",
    "                    inds[ind] = []\n",
    "                inds[ind].append(idx)\n",
    "            return inds\n",
    "\n",
    "        triplets = []\n",
    "        indices = create_indices(labels.numpy())\n",
    "        unique_labels = np.unique(labels.numpy())\n",
    "        n_classes = unique_labels.shape[0]\n",
    "        # add only unique indices in batch\n",
    "        already_idxs = set()\n",
    "\n",
    "        for x in tqdm(range(num_triplets)):\n",
    "            if len(already_idxs) >= args.batch_size:\n",
    "                already_idxs = set()\n",
    "            c1 = np.random.randint(0, n_classes)\n",
    "            while c1 in already_idxs:\n",
    "                c1 = np.random.randint(0, n_classes)\n",
    "            already_idxs.add(c1)\n",
    "            c2 = np.random.randint(0, n_classes)\n",
    "            while c1 == c2:\n",
    "                c2 = np.random.randint(0, n_classes)\n",
    "            if len(indices[c1]) == 2:  # hack to speed up process\n",
    "                n1, n2 = 0, 1\n",
    "            else:\n",
    "                n1 = np.random.randint(0, len(indices[c1]))\n",
    "                n2 = np.random.randint(0, len(indices[c1]))\n",
    "                while n1 == n2:\n",
    "                    n2 = np.random.randint(0, len(indices[c1]))\n",
    "            n3 = np.random.randint(0, len(indices[c2]))\n",
    "            triplets.append([indices[c1][n1], indices[c1][n2], indices[c2][n3]])\n",
    "        return torch.LongTensor(np.array(triplets))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        def transform_img(img):\n",
    "            if self.transform is not None:\n",
    "                img = self.transform(img.numpy())\n",
    "            return img\n",
    "\n",
    "        if not self.train:\n",
    "            m = self.matches[index]\n",
    "            img1 = transform_img(self.data[m[0]])\n",
    "            img2 = transform_img(self.data[m[1]])\n",
    "            return img1, img2, m[2]\n",
    "\n",
    "        t = self.triplets[index]\n",
    "        a, p, n = self.data[t[0]], self.data[t[1]], self.data[t[2]]\n",
    "\n",
    "        img_a = transform_img(a)\n",
    "        img_p = transform_img(p)\n",
    "        img_n = None\n",
    "        if self.out_triplets:\n",
    "            img_n = transform_img(n)\n",
    "        # transform images if required\n",
    "        if args.fliprot:\n",
    "            do_flip = random.random() > 0.5\n",
    "            do_rot = random.random() > 0.5\n",
    "            if do_rot:\n",
    "                img_a = img_a.permute(0,2,1)\n",
    "                img_p = img_p.permute(0,2,1)\n",
    "                if self.out_triplets:\n",
    "                    img_n = img_n.permute(0,2,1)\n",
    "            if do_flip:\n",
    "                img_a = torch.from_numpy(deepcopy(img_a.numpy()[:,:,::-1]))\n",
    "                img_p = torch.from_numpy(deepcopy(img_p.numpy()[:,:,::-1]))\n",
    "                if self.out_triplets:\n",
    "                    img_n = torch.from_numpy(deepcopy(img_n.numpy()[:,:,::-1]))\n",
    "        if self.out_triplets:\n",
    "            return (img_a, img_p, img_n)\n",
    "        else:\n",
    "            return (img_a, img_p)\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.train:\n",
    "            return self.triplets.size(0)\n",
    "        else:\n",
    "            return self.matches.size(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_loaders(dataset_names, load_random_triplets = False):\n",
    "    test_dataset_names = copy(dataset_names)\n",
    "    test_dataset_names.remove(args.training_set)\n",
    "\n",
    "    kwargs = {'num_workers': args.num_workers, 'pin_memory': args.pin_memory} if args.cuda else {}\n",
    "\n",
    "    np_reshape64 = lambda x: np.reshape(x, (64, 64, 1))\n",
    "    transform_test = transforms.Compose([\n",
    "            transforms.Lambda(np_reshape64),\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize(32),\n",
    "            transforms.ToTensor()])\n",
    "    transform_train = transforms.Compose([\n",
    "            transforms.Lambda(np_reshape64),\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.RandomRotation(5,PIL.Image.BILINEAR),\n",
    "            transforms.RandomResizedCrop(32, scale = (0.9,1.0),ratio = (0.9,1.1)),\n",
    "            transforms.Resize(32),\n",
    "            transforms.ToTensor()])\n",
    "    transform = transforms.Compose([\n",
    "            transforms.Lambda(cv2_scale),\n",
    "            transforms.Lambda(np_reshape),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((args.mean_image,), (args.std_image,))])\n",
    "    if not args.augmentation:\n",
    "        transform_train = transform\n",
    "        transform_test = transform\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "            TripletPhotoTour(train=True,\n",
    "                             load_random_triplets = load_random_triplets,\n",
    "                             batch_size=args.batch_size,\n",
    "                             root=args.dataroot,\n",
    "                             name=args.training_set,\n",
    "                             download=True,\n",
    "                             transform=transform_train),\n",
    "                             batch_size=args.batch_size,\n",
    "                             shuffle=True, **kwargs)\n",
    "\n",
    "    test_loaders = [{'name': name,\n",
    "                     'dataloader': torch.utils.data.DataLoader(\n",
    "             TripletPhotoTour(train=False,\n",
    "                     batch_size=args.test_batch_size,\n",
    "                     root=args.dataroot,\n",
    "                     name=name,\n",
    "                     download=True,\n",
    "                     transform=transform_test),\n",
    "                        batch_size=args.test_batch_size,\n",
    "                        shuffle=False, **kwargs)}\n",
    "                    for name in test_dataset_names]\n",
    "\n",
    "    return train_loader, test_loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "\n",
    "Load the Photo Tourism dataset by PyTorch. Below line (function 'create_loader') will help you to download the dataset to your directory. The data dir and other configuration setings are specified in config_profile.py.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Found cached data data/sets/liberty.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/100000 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 100000 triplets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  8%|▊         | 7848/100000 [00:00<00:01, 78478.20it/s]\u001b[A\n",
      " 14%|█▍        | 14429/100000 [00:00<00:01, 74193.32it/s]\u001b[A\n",
      " 25%|██▌       | 25106/100000 [00:00<00:00, 81667.58it/s]\u001b[A\n",
      " 36%|███▌      | 35837/100000 [00:00<00:00, 87974.00it/s]\u001b[A\n",
      " 46%|████▌     | 46021/100000 [00:00<00:00, 91719.06it/s]\u001b[A\n",
      " 56%|█████▋    | 56489/100000 [00:00<00:00, 95255.32it/s]\u001b[A\n",
      " 67%|██████▋   | 66741/100000 [00:00<00:00, 97323.24it/s]\u001b[A\n",
      " 76%|███████▌  | 75994/100000 [00:00<00:00, 74998.02it/s]\u001b[A\n",
      " 87%|████████▋ | 86520/100000 [00:00<00:00, 82076.40it/s]\u001b[A\n",
      " 98%|█████████▊| 97785/100000 [00:01<00:00, 89351.10it/s]\u001b[A\n",
      "100%|██████████| 100000/100000 [00:01<00:00, 89934.31it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Found cached data data/sets/notredame.pt\n",
      "# Found cached data data/sets/yosemite.pt\n"
     ]
    }
   ],
   "source": [
    "dataset_names = ['liberty', 'notredame', 'yosemite']\n",
    "train_loader, test_loaders = create_loaders(dataset_names, load_random_triplets = args.load_random_triplets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##  Visualizaiton of the Training and Testing Data\n",
    "Below are some examples of patches in this dataset.\n",
    "\n",
    "#### Training\n",
    "In the training phase, the input data is a batch of patch pairs: X = {(patch_a, patch_p)}, which represents the anchor patch and the positive patch, respectively. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN TRAINing, each data entry has 2 elements, each with size of: \n",
      "torch.Size([1024, 1, 32, 32])\n",
      "Below two rows images are 3 examples for patch_a and patch_p\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nrow = 3  \n",
    "def plot_examples(img_tensor, nrow):  \n",
    "    fig, axs = plt.subplots(1, nrow)\n",
    "    for i, ax in enumerate(axs):\n",
    "        img = img_tensor[i, 0]\n",
    "        ax.imshow(img, cmap='gray')\n",
    "        ax.axis('off')\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    print(\"IN TRAINing, each data entry has {} elements, each with size of: \".format(len(sample_batched)))\n",
    "    print(sample_batched[0].shape)\n",
    "    print(\"Below two rows images are {} examples for patch_a and patch_p\".format(nrow))\n",
    "    if i_batch == 0:\n",
    "        plot_examples(sample_batched[0], nrow)\n",
    "        plot_examples(sample_batched[1], nrow)\n",
    "        plt.show()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing\n",
    "In the testing phase, the input data is a batch of patch pairs, and a label that indicates the matching result of this pair (1 means match and 0 means not match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN TESTING, each data entry has 3 elements, with size of: torch.Size([1024, 1, 32, 32]), torch.Size([1024, 1, 32, 32]), and torch.Size([1024])\n",
      "\n",
      "Below two rows images are 3 examples for for patch_a and patch_p.\n",
      "labels are : tensor([0, 0, 1])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i_batch, sample_batched in enumerate(test_loaders[0]['dataloader']):\n",
    "    print(\"IN TESTING, each data entry has {} elements, with size of: {}, {}, and {}\".format(len(sample_batched), \n",
    "                                                                                             sample_batched[0].shape, \n",
    "                                                                                             sample_batched[1].shape, \n",
    "                                                                                             sample_batched[2].shape))\n",
    "    print(\"\\nBelow two rows images are {} examples for for patch_a and patch_p.\".format(nrow))\n",
    "    if i_batch == 0:\n",
    "        plot_examples(sample_batched[0], nrow)\n",
    "        plot_examples(sample_batched[1], nrow)\n",
    "        print(\"labels are :\", sample_batched[2][:nrow])\n",
    "        plt.show()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Build Network Model\n",
    "The DesNet is a simple CNN network, which only contains two CNN blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load network\n",
    "from descriptor import DesNet\n",
    "from descriptor2 import DesNet_2\n",
    "from descriptor3 import DesNet_3\n",
    "#model = DesNet()\n",
    "model1 = DesNet()\n",
    "model2 = DesNet_2()\n",
    "model3 = DesNet_3()\n",
    "\n",
    "model = model3;\n",
    "outputs = []\n",
    "accuracylistnotredame = []\n",
    "accuracylistyosemite = []\n",
    "\n",
    "if args.cuda:\n",
    "        model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define optimize\n",
    "We will use SGD, but you can change it to ADAM by modifying arg.lr in config_profile.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimizer\n",
    "def create_optimizer(model, new_lr):\n",
    "    # setup optimizer\n",
    "    if args.optimizer == 'sgd':\n",
    "        optimizer = optim.SGD(model.parameters(), lr=new_lr,\n",
    "                              momentum=0.9, dampening=0.9,\n",
    "                              weight_decay=args.wd)\n",
    "    elif args.optimizer == 'adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=new_lr,\n",
    "                               weight_decay=args.wd)\n",
    "    else:\n",
    "        raise Exception('Not supported optimizer: {0}'.format(args.optimizer))\n",
    "    return optimizer\n",
    "optimizer1 = create_optimizer(model.features, args.lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a training module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, optimizer, epoch, logger, load_triplets  = False):\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    pbar = tqdm(enumerate(train_loader))\n",
    "    for batch_idx, data in pbar:\n",
    "        if load_triplets:\n",
    "            data_a, data_p, data_n = data\n",
    "        else:\n",
    "            data_a, data_p = data\n",
    "\n",
    "        if args.cuda:\n",
    "            data_a, data_p  = data_a.cuda(), data_p.cuda()\n",
    "            data_a, data_p = Variable(data_a), Variable(data_p)\n",
    "            out_a = model(data_a)\n",
    "            out_p = model(data_p)\n",
    "        if load_triplets:\n",
    "            data_n  = data_n.cuda()\n",
    "            data_n = Variable(data_n)\n",
    "            out_n = model(data_n)\n",
    "        \n",
    "        \n",
    "        loss = loss_DesNet(out_a, out_p,\n",
    "                        margin=args.margin,\n",
    "                        anchor_swap=args.anchorswap,\n",
    "                        anchor_ave=args.anchorave,\n",
    "                        batch_reduce = args.batch_reduce,\n",
    "                        loss_type = args.loss)\n",
    "\n",
    "        if args.decor:\n",
    "            loss += CorrelationPenaltyLoss()(out_a)\n",
    "            \n",
    "        if args.gor:\n",
    "            loss += args.alpha*global_orthogonal_regularization(out_a, out_n)\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        adjust_learning_rate(optimizer)\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            pbar.set_description(\n",
    "                'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data_a), len(train_loader.dataset),\n",
    "                           100. * batch_idx / len(train_loader),\n",
    "                    loss.item()))\n",
    "\n",
    "\n",
    "    if (args.enable_logging):\n",
    "#         logger.log_value('loss', loss.data[0]).step()\n",
    "        logger.log_value('loss', loss.item()).step()\n",
    "\n",
    "    try:\n",
    "        os.stat('{}{}'.format(args.model_dir,suffix))\n",
    "    except:\n",
    "        os.makedirs('{}{}'.format(args.model_dir,suffix))\n",
    "\n",
    "    torch.save({'epoch': epoch + 1, 'state_dict': model.state_dict()},\n",
    "               '{}{}/checkpoint_{}.pth'.format(args.model_dir,suffix,epoch))\n",
    "        \n",
    "    outputs.append(loss.item())\n",
    "\n",
    "    \n",
    "def adjust_learning_rate(optimizer):\n",
    "    \"\"\"Updates the learning rate given the learning rate decay.\n",
    "    The routine has been implemented according to the original Lua SGD optimizer\n",
    "    \"\"\"\n",
    "    for group in optimizer.param_groups:\n",
    "        if 'step' not in group:\n",
    "            group['step'] = 0.\n",
    "        else:\n",
    "            group['step'] += 1.\n",
    "        group['lr'] = args.lr * (\n",
    "        1.0 - float(group['step']) * float(args.batch_size) / (args.n_triplets * float(args.epochs)))\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a test module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_loader, model, epoch, logger, logger_test_name):\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    labels, distances = [], []\n",
    "\n",
    "    pbar = tqdm(enumerate(test_loader))\n",
    "    for batch_idx, (data_a, data_p, label) in pbar:\n",
    "        # data_a.shape= torch.Size([1024, 1, 32, 32]) \n",
    "        # data_p.shape =torch.Size([1024, 1, 32, 32]) \n",
    "        # label.shape = torch.Size([1024])\n",
    "        if args.cuda:\n",
    "            data_a, data_p = data_a.cuda(), data_p.cuda()\n",
    "\n",
    "        data_a, data_p, label = Variable(data_a, volatile=True), \\\n",
    "                                Variable(data_p, volatile=True), Variable(label)\n",
    "        out_a = model(data_a)\n",
    "        out_p = model(data_p)\n",
    "        dists = torch.sqrt(torch.sum((out_a - out_p) ** 2, 1))  # euclidean distance\n",
    "        distances.append(dists.data.cpu().numpy().reshape(-1,1))\n",
    "        ll = label.data.cpu().numpy().reshape(-1, 1)\n",
    "        labels.append(ll)\n",
    "\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            pbar.set_description(logger_test_name+' Test Epoch: {} [{}/{} ({:.0f}%)]'.format(\n",
    "                epoch, batch_idx * len(data_a), len(test_loader.dataset),\n",
    "                       100. * batch_idx / len(test_loader)))\n",
    "\n",
    "    num_tests = test_loader.dataset.matches.size(0)\n",
    "    labels = np.vstack(labels).reshape(num_tests)\n",
    "    distances = np.vstack (distances).reshape(num_tests)\n",
    "\n",
    "    fpr95 = ErrorRateAt95Recall(labels, 1.0 / (distances + 1e-8))\n",
    "    print('\\33[91mTest set: Accuracy(FPR95): {:.8f}\\n\\33[0m'.format(fpr95))\n",
    "    if logger_test_name == \"yosemite\":\n",
    "        accuracylistyosemite.append(fpr95)\n",
    "    if logger_test_name == \"notredame\":\n",
    "        accuracylistnotredame.append(fpr95)\n",
    "\n",
    "    if (args.enable_logging):\n",
    "        logger.log_value(logger_test_name+' fpr95', fpr95)\n",
    "    return\n",
    "\n",
    "\n",
    "def ErrorRateAt95Recall(labels, scores):\n",
    "    distances = 1.0 / (scores + 1e-8)\n",
    "    recall_point = 0.95\n",
    "    labels = labels[np.argsort(distances)]\n",
    "    # Sliding threshold: get first index where recall >= recall_point. \n",
    "    # This is the index where the number of elements with label==1 below the threshold reaches a fraction of \n",
    "    # 'recall_point' of the total number of elements with label==1. \n",
    "    # (np.argmax returns the first occurrence of a '1' in a bool array). \n",
    "    threshold_index = np.argmax(np.cumsum(labels) >= recall_point * np.sum(labels)) \n",
    "\n",
    "    FP = np.sum(labels[:threshold_index] == 0) # Below threshold (i.e., labelled positive), but should be negative\n",
    "    TN = np.sum(labels[threshold_index:] == 0) # Above threshold (i.e., labelled negative), and should be negative\n",
    "    return float(FP) / float(FP + TN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 24.50 MiB (GPU 0; 10.92 GiB total capacity; 3.93 GiB already allocated; 20.50 MiB free; 40.23 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-cfc19a5e982c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# iterate over test loaders and test results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtriplet_flag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loaders\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dataloader'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-83a537a395ab>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, optimizer, epoch, logger, load_triplets)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mdata_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_p\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mdata_a\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mdata_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mout_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mout_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mload_triplets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/massonm/CNN_keypoints_description/descriptor3.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mx_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mL2Norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenv/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenv/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             exponential_average_factor, self.eps)\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenv/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   1621\u001b[0m     return torch.batch_norm(\n\u001b[1;32m   1622\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1623\u001b[0;31m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1624\u001b[0m     )\n\u001b[1;32m   1625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 24.50 MiB (GPU 0; 10.92 GiB total capacity; 3.93 GiB already allocated; 20.50 MiB free; 40.23 MiB cached)"
     ]
    }
   ],
   "source": [
    "start = args.start_epoch\n",
    "end = start + args.epochs\n",
    "logger, file_logger = None, None\n",
    "triplet_flag = args.load_random_triplets\n",
    "from Losses import loss_DesNet\n",
    "TEST_ON_W1BS = True\n",
    "LOG_DIR = args.log_dir\n",
    "if(args.enable_logging):\n",
    "    from Loggers import Logger, FileLogger\n",
    "    logger = Logger(LOG_DIR)\n",
    "    \n",
    "suffix = '{}_{}_{}'.format(args.experiment_name, args.training_set, args.batch_reduce)\n",
    "if args.gor:\n",
    "    suffix = suffix+'_gor_alpha{:1.1f}'.format(args.alpha)\n",
    "if args.anchorswap:\n",
    "    suffix = suffix + '_as'\n",
    "if args.anchorave:\n",
    "    suffix = suffix + '_av'\n",
    "if args.fliprot:\n",
    "        suffix = suffix + '_fliprot'\n",
    "\n",
    "res_fpr_liberty = torch.zeros(end-start,1)\n",
    "res_fpr_notredame = torch.zeros(end-start, 1)\n",
    "res_fpr_yosemite = torch.zeros(end-start, 1)\n",
    "\n",
    "epochlist = []\n",
    "\n",
    "for epoch in range(start, end):\n",
    "\n",
    "    # iterate over test loaders and test results\n",
    "    train(train_loader, model, optimizer1, epoch, logger, triplet_flag)\n",
    "    for test_loader in test_loaders:\n",
    "        test(test_loader['dataloader'], model, epoch, logger, test_loader['name'])\n",
    "\n",
    "    #randomize train loader batches\n",
    "    train_loader, test_loaders2 = create_loaders(args.dataset_names, load_random_triplets=triplet_flag)\n",
    "    epochlist.append(epoch)\n",
    "\n",
    "fname = 'output.csv'\n",
    "with open(fname, 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    for row_index in range(len(outputs)):\n",
    "        row = [epochlist[row_index], outputs[row_index]]\n",
    "        writer.writerow(row)\n",
    "        \n",
    "fname = 'accuracynotredame.csv'\n",
    "with open(fname, 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    for row_index in range(len(accuracylistnotredame)):\n",
    "        row = [epochlist[row_index], accuracylistnotredame[row_index]]\n",
    "        writer.writerow(row)\n",
    "        \n",
    "fname = 'accuracyyosemite.csv'\n",
    "with open(fname, 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    for row_index in range(len(accuracylistnotredame)):\n",
    "        row = [epochlist[row_index], accuracylistyosemite[row_index]]\n",
    "        writer.writerow(row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### KEYPOINTS DESCRIPTION USING THE TRAINED CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([5, 200, 1, 32, 32])\n",
      "torch.Size([1000, 1, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# load patches\n",
    "patches = torch.load(\"patches_notredame/patches_notredame.pt\")\n",
    "print(type(patches))\n",
    "print(patches.shape)\n",
    "patches = patches.view(-1, 1, 32, 32).cuda()\n",
    "print(patches.shape)\n",
    "\n",
    "#output.data.cpu().numpy().shape = torch.Size([1000, 128])\n",
    "\n",
    "#patch = patch.view(-1, 1, 32, 32).cuda()\n",
    "#output = model1(patch)\n",
    "#print(output.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './models/model1_2014/_liberty_min_as_fliprot/checkpoint_39.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-3dbc2a26997f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Load weights model 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrained_weight_1_1024\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./models/model1_2014/_liberty_min_as_fliprot/checkpoint_39.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrained_weight_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./models/model1_2014/_liberty_min_as_fliprot/checkpoint_39.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_weight_1_1024\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenv/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[1;32m    363\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './models/model1_2014/_liberty_min_as_fliprot/checkpoint_39.pth'"
     ]
    }
   ],
   "source": [
    "#Load weights model 1\n",
    "trained_weight_1_1024 = torch.load(\"./models/model1_2014/_liberty_min_as_fliprot/checkpoint_39.pth\")\n",
    "trained_weight_1 = torch.load(\"./models/model1_2014/_liberty_min_as_fliprot/checkpoint_39.pth\")\n",
    "model1.load_state_dict(trained_weight_1_1024['state_dict'])\n",
    "\n",
    "#Forward pass the patches to the model 1\n",
    "output1 = model1(patches)\n",
    "\n",
    "#Resize, output1 result\n",
    "output1.data.cpu().numpy().shape = torch.Size([1000, 128])\n",
    "out1 = output1.view(5, 200, 128).cpu().data\n",
    "#output.data.cpu().numpy().shape = torch.Size([1000, 128])\n",
    "\n",
    "\n",
    "print(out1.shape)\n",
    "output_dir = \"CNN1-1024-notredame-keypoints-descriptions.pt\"\n",
    "torch.save(out2, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 3200000 into shape (1000,128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-c8000aa6eb2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#Resize, output1 result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0moutput2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mout2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#output.data.cpu().numpy().shape = torch.Size([1000, 128])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 3200000 into shape (1000,128)"
     ]
    }
   ],
   "source": [
    "#Load weights model 2\n",
    "trained_weight_2_1024 = torch.load(\"./models/model2_1024/_liberty_min_as_fliprot/checkpoint_39.pth\")\n",
    "trained_weight_2 = torch.load(\"./models/model2_512/_liberty_min_as_fliprot/checkpoint_39.pth\")\n",
    "model2.load_state_dict(trained_weight_2_1024['state_dict'])\n",
    "\n",
    "#Forward pass the patches to the model 1\n",
    "output2 = model2(patches)\n",
    "\n",
    "#Resize, output1 result\n",
    "output2.data.cpu().numpy().shape = torch.Size([1000, 128])\n",
    "out2 = output2.view(5, 200, 128).cpu().data\n",
    "#output.data.cpu().numpy().shape = torch.Size([1000, 128])\n",
    "\n",
    "print(out2.shape)\n",
    "output_dir = \"CNN2-1024-notredame-keypoints-descriptions.pt\"\n",
    "torch.save(out2, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'patches' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-41b2dd4d2c0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#Forward pass the patches to the model 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0moutput3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#Resize, output1 result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'patches' is not defined"
     ]
    }
   ],
   "source": [
    "#Load weights model 3\n",
    "#trained_weight_3_1024 = torch.load(\"./models/model3_1024/_liberty_min_as_fliprot/checkpoint_39.pth\")\n",
    "trained_weight_3 = torch.load(\"./models/model3_512/_liberty_min_as_fliprot/checkpoint_39.pth\")\n",
    "model3.load_state_dict(trained_weight_3['state_dict'])\n",
    "\n",
    "#Forward pass the patches to the model 1\n",
    "output3 = model3(patches)\n",
    "\n",
    "#Resize, output1 result\n",
    "output3.data.cpu().numpy().shape = torch.Size([1000, 128])\n",
    "out3 = output3.view(5, 200, 128).cpu().data\n",
    "#output.data.cpu().numpy().shape = torch.Size([1000, 128])\n",
    "\n",
    "print(out3.shape)\n",
    "output_dir = \"CNN3-512-notredame-keypoints-descriptions.pt\"\n",
    "torch.save(out3, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 200, 128])\n"
     ]
    }
   ],
   "source": [
    "#Store themtogether:\n",
    "#all_output = torch.stack((out1, out2, out3))\n",
    "print(out1.shape)\n",
    "output_dir = \"CNN1-1024-notredame-keypoints-descriptions.pt\"\n",
    "torch.save(out1, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
